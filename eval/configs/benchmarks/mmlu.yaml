# MMLU (Massive Multitask Language Understanding)
# 57 diverse academic tasks covering STEM, humanities, social sciences, and more
# Standard benchmark for evaluating language model knowledge

model:
  model_name: "meta-llama/Llama-3.1-8B-Instruct"
  # Or use your fine-tuned checkpoint:
  # model_name: "./output/llama8b_lora"
  model_max_length: 2048
  dtype: "bfloat16"
  attn_implementation: "flash_attention_2"

generation:
  per_device_batch_size: 4
  temperature: 0.0  # Greedy decoding for evaluation
  max_new_tokens: 512

tasks:
  - backend: "lm_harness"
    task: "mmlu"
    num_fewshot: 5  # 5-shot evaluation (standard)
    output_path: "./eval_results/mmlu"

  # Can also evaluate specific MMLU subtasks
  # - backend: "lm_harness"
  #   task: "mmlu_college_computer_science"
  #   num_fewshot: 5
  # - backend: "lm_harness"
  #   task: "mmlu_college_mathematics"
  #   num_fewshot: 5
